{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection\n",
    "In this notebook, we pull stock and company financials data from alpha vantage.\n",
    "First, we import the necessary packages below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import usual packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import usual packages for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import datetime to get the current date\n",
    "import datetime as dt\n",
    "\n",
    "#import alpha vantage packages\n",
    "from alpha_vantage.timeseries import TimeSeries #for stock data\n",
    "from alpha_vantage.techindicators import TechIndicators #for technical indicators\n",
    "from alpha_vantage.fundamentaldata import FundamentalData #for company overview\n",
    "from alpha_vantage.alphaintelligence import AlphaIntelligence #for news sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use alpha vantage, we need an API key, which can be obtained at this link:\n",
    "<https://www.alphavantage.co/support/#api-key>\n",
    "\n",
    "Note: the free API key allows up to 25 queries per day.\n",
    "\n",
    "After obtaining our personal key, we initialize the four classes from which we will pull data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arvind's API key\n",
    "# my_key='DJ3QKKTFZ5J298QY'\n",
    "# ts = TimeSeries(key=my_key, output_format='pandas')\n",
    "# fd = FundamentalData(key=my_key, output_format='pandas')\n",
    "# ai = AlphaIntelligence(key=my_key, output_format='pandas')\n",
    "Julies_key = '94ZVK4ONX7DLJNGE'\n",
    "ts = TimeSeries(key=Julies_key, output_format='pandas')\n",
    "fd = FundamentalData(key=Julies_key, output_format='pandas')\n",
    "ai = AlphaIntelligence(key=Julies_key, output_format='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a few simple functions that will pull the data, apply some pre-processing, and then save to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get stock data and save to csv\n",
    "def stock_to_csv(ticker):\n",
    "    df, _ = ts.get_daily(symbol=ticker, outputsize='full')\n",
    "    df.columns = ['open','high','low','close','volume']\n",
    "    df.sort_index(inplace=True)\n",
    "    df = df[df.index.year >= 2014]\n",
    "    df.to_csv(f'../data/{ticker}_stock.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticker_news_to_csv(ticker):\n",
    "    df, _ = ai.get_news_sentiment(tickers = ticker, time_from='20220810T0130', limit=1000)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df.to_csv(f'../data/{ticker}_news_data_raw.csv')\n",
    "    #choose only the date and news sentiment score columns\n",
    "    df = pd.DataFrame({'date': pd.to_datetime(df['time_published']).dt.date,\n",
    "                       'ticker_sentiment': df['ticker_sentiment']})\n",
    "    df = df.groupby('date').sum()\n",
    "    scores = [] #to store daily sentiment scores for aapl\n",
    "    relevances = [] #to store daily relevance scores for aapl\n",
    "    for i in range(len(df)):\n",
    "        temp = pd.DataFrame(df['ticker_sentiment'].iloc[i])\n",
    "        temp = temp[temp['ticker'] == ticker]\n",
    "        wts = temp['relevance_score'].astype(float)\n",
    "        raw_scores = temp['ticker_sentiment_score'].astype(float)\n",
    "        #append the mean relevance score for the day\n",
    "        relevances.append(wts.mean())\n",
    "        #append the weighted average sentiment score for the day\n",
    "        scores.append(np.dot(wts,raw_scores) / wts.sum())\n",
    "    # df[f'{ticker}_sentiment_score'] = np.array(scores)\n",
    "    # df[f'{ticker}_relevance_score'] = np.array(relevances)\n",
    "    df[f'sentiment_score'] = np.array(scores)\n",
    "    df[f'relevance_score'] = np.array(relevances)\n",
    "    df.drop('ticker_sentiment', axis=1, inplace=True)\n",
    "    df.to_csv(f'../data/{ticker}_news_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def financial_cleaner(df):\n",
    "    df['date'] = pd.to_datetime(df['fiscalDateEnding'])\n",
    "    df.drop(columns='fiscalDateEnding',inplace=True)\n",
    "    df.set_index('date',inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df = df[df.index.year >= 2014]\n",
    "    return df\n",
    "\n",
    "def financials_to_csv(ticker):\n",
    "    df_e, _ = fd.get_earnings_quarterly(ticker)\n",
    "    df_b, _ = fd.get_balance_sheet_quarterly(ticker)\n",
    "    df_i, _ = fd.get_income_statement_quarterly(ticker)\n",
    "    df_e.drop(columns=['reportTime'],inplace=True)\n",
    "    df_b.drop(columns=['reportedCurrency'], inplace=True)\n",
    "    df_i.drop(columns=['reportedCurrency'], inplace=True)\n",
    "    #cleaning the data\n",
    "    df_b = financial_cleaner(df_b)\n",
    "    df_i = financial_cleaner(df_i)\n",
    "    df_e = financial_cleaner(df_e)\n",
    "    #concatenating the dataframes\n",
    "    df_financials = pd.concat([df_b,df_i,df_e],axis=1)\n",
    "    df_financials.to_csv(f'../data/{ticker}_financials.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that it all works by setting the ticker to NVDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = 'NVDA'\n",
    "# stock_to_csv(ticker)\n",
    "# ticker_news_to_csv(ticker)\n",
    "# financials_to_csv(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in the csv's, some care is needed to ensure that the dtypes of the columns are correctly interpreted. For convenience, we wrap this in a simple function that pulls the data for a given ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ticker):\n",
    "    df_stock = pd.read_csv(f'../data/{ticker}_stock.csv', index_col='date',parse_dates=True,dtype=float)\n",
    "    df_news = pd.read_csv(f'../data/{ticker}_news_data.csv', index_col='date',parse_dates=True,dtype=float)\n",
    "    df_financials = pd.read_csv(f'../data/{ticker}_financials.csv', \n",
    "                                index_col='date',\n",
    "                                parse_dates=True,\n",
    "                                dtype={col: 'float' for col in pd.read_csv(f'../data/{ticker}_financials.csv', nrows=1).columns if col!='reportedDate'},\n",
    "                                na_values='None')\n",
    "    return {'stock': df_stock, \n",
    "            'news' : df_news, \n",
    "            'financials' : df_financials}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvda = get_data('NVDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvda['financials']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = 'TSLA'\n",
    "# stock_to_csv(ticker)\n",
    "# ticker_news_to_csv(ticker)\n",
    "# financials_to_csv(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsla = get_data('TSLA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsla['financials']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = 'META'\n",
    "# stock_to_csv(ticker)\n",
    "# ticker_news_to_csv(ticker)\n",
    "# financials_to_csv(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta = get_data('META')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = 'NFLX'\n",
    "# stock_to_csv(ticker)\n",
    "# ticker_news_to_csv(ticker)\n",
    "# financials_to_csv(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nflx = get_data('NFLX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nflx['news']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a loop to get ticker sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Thank you for using Alpha Vantage! Our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m tickers \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJPM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLLY\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSFT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m tickers:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mticker_news_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mticker_news_to_csv\u001b[0;34m(ticker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mticker_news_to_csv\u001b[39m(ticker):\n\u001b[0;32m----> 2\u001b[0m     df, _ \u001b[38;5;241m=\u001b[39m \u001b[43mai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_news_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m20220810T0130\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     df\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_news_data_raw.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/alpha_vantage/alphavantage.py:218\u001b[0m, in \u001b[0;36mAlphaVantage._output_format.<locals>._format_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 218\u001b[0m     call_response, data_key, meta_data_key \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_format\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_format\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/alpha_vantage/alphavantage.py:160\u001b[0m, in \u001b[0;36mAlphaVantage._call_api_on_func.<locals>._call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(url, apikey_parameter)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m, data_key, meta_data_key\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/alpha_vantage/alphavantage.py:361\u001b[0m, in \u001b[0;36mAlphaVantage._handle_api_call\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(json_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError Message\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_response \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtreat_info_as_error:\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(json_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_response \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtreat_info_as_error:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(json_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: Thank you for using Alpha Vantage! Our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits."
     ]
    }
   ],
   "source": [
    "# tickers = ['AAPL', 'AMZN', 'COST', 'DIS', 'GOOGL', 'JPM', 'LLY',  'MSFT','META', 'NFLX', 'NVDA', 'TSLA']\n",
    "tickers = [ 'JPM', 'LLY',  'MSFT']\n",
    "\n",
    "for ticker in tickers:\n",
    "    ticker_news_to_csv(ticker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
